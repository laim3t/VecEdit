# 项目核心数据操作（增删改）逻辑分析

本文档深入分析项目核心的数据操作逻辑，包括行的添加（Create）、删除（Delete）和更新（Update），基于对 `RobustVectorDataHandler` 类的代码分析得出。

## 1. 核心架构：索引与数据分离

项目采用了一种高性能的混合存储模型：

- **SQLite 数据库**: 存储元数据和**行索引**。关键表是 `VectorTableRowIndex`，它为每一逻辑行记录了其在二进制文件中的物理位置（`offset`）和大小（`size`）。
- **二进制文件 (`.vbindata`)**: 存储原始的、经过序列化的**行数据**。

这种架构将“在哪里找到数据”（索引）和“数据本身”分离开来，使得对索引的操作可以非常快速，而无需改动庞大的数据文件，是所有高性能操作的基础。

## 2. 添加 (Create) 操作逻辑

添加新行的操作由 `RobustVectorDataHandler::insertVectorRows` 函数处理，其核心思想是 **“只追加” (Append-Only)**，为批量插入进行了深度优化。

1. **性能优先**: 函数开始时会设置一系列 SQLite `PRAGMA` 指令，将数据库性能调整为最优插入模式（如关闭同步、使用内存日志等）。
2. **事务包裹**: 所有数据库操作均在一个事务内完成，确保数据的一致性和原子性。
3. **处理插入位置**:
    - **末尾追加**: 如果是在表格末尾添加新行，这是最高效的路径。
    - **中间插入**: 如果是在表格中间插入，操作会稍微复杂。它会先对数据库中的 `VectorTableRowIndex` 表执行 `UPDATE`，将插入点之后所有行的 `logical_row_order` (逻辑行号) 集体增加，为新行“腾出”逻辑空间。
4. **数据写入**:
    - 函数以 **追加模式 (`Append`)** 打开二进制文件。
    - 所有待添加的新行数据被序列化后，**一次性、顺序地写入到二进制文件的末尾**。这避免了随机I/O，是性能的关键。
5. **索引更新**:
    - 在写入二进制文件的同时，记录下每个新行在文件中的 `offset` 和 `size`。
    - 使用预编译的 `INSERT` 语句和 `execBatch()` 方法，将所有新行的索引信息**批量插入**到 `VectorTableRowIndex` 表中。

**总结**: “添加”是一个对批量操作极度友好的过程。它将所有物理数据高效地追加到二进制文件末尾，然后通过一次批量数据库操作更新索引，实现了极高的插入性能。

## 3. 删除 (Delete) 操作逻辑

删除操作由 `RobustVectorDataHandler::deleteVectorRows` 函数处理，其核心思想是 **“逻辑删除” (Soft Delete)**，追求极致的执行效率。

1. **不触碰二进制文件**: 删除操作**完全不会修改或读取**庞大的二进制数据文件。这避免了成本高昂的文件整理操作。
2. **标记索引为无效**: 操作的核心是向 `VectorTableRowIndex` 表发送一条 `UPDATE` 命令。
3. **`is_active` 标志**: 对于要删除的每一行，函数将其在索引表中的 `is_active` 标志位从 `1` 更新为 `0`。
4. **更新总行数**: 在标记完所有要删除的行后，函数会更新 `VectorTableMasterRecord` 主记录表中的 `row_count`，将其减去已删除的行数。
5. **数据成为“垃圾”**: 被标记为无效的行所对应的二进制数据虽然物理上还存在，但在逻辑上已不可访问，成为待回收的“垃圾数据”。这为后续的“垃圾回收”机制提供了基础。

**总结**: “删除”是一个非常轻量级的纯数据库操作。它通过改变索引表中的一个标志位来“假装”数据已被删除，速度极快，几乎不受数据量的影响。

## 4. 更新 (Update) 操作逻辑

更新操作由 `RobustVectorDataHandler::updateVectorRow` 函数处理，它采用了一种非常巧妙的 **“智能混合策略”**。

1. **数据序列化**: 首先，将更新后的行数据序列化为字节数组。
2. **获取旧尺寸**: 查询 `VectorTableRowIndex` 表，获取该行更新前在二进制文件中的 `offset` 和 `size`。
3. **尺寸比较与决策**: 这是策略的核心，比较新数据的尺寸 (`newSize`) 和旧数据的尺寸 (`oldSize`)：
    - **情况A：`newSize <= oldSize` (原位更新)**
        - 如果新数据不比旧数据大，它可以直接放回原来的“坑”里。
        - 函数会直接定位到文件中的 `oldOffset`，用新数据**覆盖**旧数据。这是最高效的更新方式。
        - 如果新数据比旧数据小，会留下一小块无法使用的“碎片空间”，但在整体模型中可以接受。
    - **情况B：`newSize > oldSize` (追加更新)**
        - 如果新数据比旧数据大，原来的“坑”放不下了。
        - 此时，操作回退到与“添加”类似的逻辑：在二进制文件的**末尾追加**新的行数据，并记录其新的 `offset` 和 `size`。
        - 旧数据所在的区域成为“垃圾数据”。
4. **更新索引**: 无论采用哪种策略，最后一步都是对 `VectorTableRowIndex` 表执行 `UPDATE`，将该行的 `offset` 和 `size` 更新为新的值，确保索引指向正确的数据位置。

**总结**: “更新”操作是效率和空间权衡的结果。它优先尝试最高效的原位更新，只在必要时才执行追加写操作，并通过最后统一的索引更新来确保数据一致性。
